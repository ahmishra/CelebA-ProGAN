{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CelebA_ProGAN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDislP3SLJ3q"
      },
      "source": [
        "# **One time execute cell**\n",
        "**Run this to save time and only see the generated faces and not the entire paper!**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0J1YQLVF0VX"
      },
      "source": [
        "# Prerequisites:\n",
        "# Tensorflow 2.0+ (pip install --upgrade tensorflow)\n",
        "# PIL (Built-in to Python)\n",
        "# Tensorflow Hub (pip install --upgrade tensorflow-hub)\n",
        "\n",
        "# AUTHOR: Aryan Mishra (https://www.github.com/ahmishra)\n",
        "\n",
        "# GOOGLE COLAB NOTEBOOK: https://www.shorturl.at/kqzE2\n",
        "# GITHUB: https://github.com/ahmishra/CelebA-ProGAN\n",
        "\n",
        "from time import time\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "start = time()\n",
        "verbose = True\n",
        "\n",
        "if verbose:\n",
        "    print(\"[INFO] Loading libraries\")\n",
        "\n",
        "from tensorflow.image import convert_image_dtype\n",
        "from tensorflow.random import normal\n",
        "from tensorflow import constant\n",
        "from tensorflow_hub import load\n",
        "from tensorflow import Variable\n",
        "from tensorflow import uint8\n",
        "\n",
        "from matplotlib.pyplot import imshow, show, tick_params\n",
        "from PIL.Image import fromarray\n",
        "\n",
        "if verbose:\n",
        "    print(\"[INFO] Loading helpers\")\n",
        "\n",
        "def display_image(image):\n",
        "  image = constant(image)\n",
        "  image = convert_image_dtype(image, uint8)\n",
        "  tick_params(left=False, right=False, labelleft=False, labelbottom=False, bottom=False)\n",
        "  imshow(image.numpy())\n",
        "  show()\n",
        "\n",
        "if verbose:\n",
        "    print(\"[GEN] Generating face...\")\n",
        "\n",
        "latent_dim = 512\n",
        "progan = load(\"https://tfhub.dev/google/progan-128/1\").signatures['default']\n",
        "initial_vector = normal([1, latent_dim])\n",
        "vector = Variable(initial_vector)\n",
        "image = progan(vector.read_value())['default'][0]\n",
        "\n",
        "if verbose:\n",
        "    print(\"[INFO] Displaying generated face...\")\n",
        "    print(f\"Finished in {round(time() - start, 2)}s\")\n",
        "    \n",
        "display_image(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xt3Kx3vBW7F"
      },
      "source": [
        "# Get started (Full paper below)\n",
        "\n",
        "## **Generating artificial faces with [CelebA Progressive GAN Model](https://tfhub.dev/google/progan-128/1)**\n",
        "\n",
        "<br>\n",
        "\n",
        "#### Author: **[Aryan Mishra](https://github.com/ahmishra)**\n",
        "#### Model download: **https://tfhub.dev/google/progan-128/1**\n",
        "\n",
        "<br>\n",
        "\n",
        "This Colab demonstrates use of a TF Hub module based on a generative adversarial network (GAN). The module maps from N-dimensional vectors, called latent space, to RGB images.\n",
        "\n",
        "Two examples are provided:\n",
        "* **Mapping** from latent space to images, and\n",
        "* Given a target image, **using gradient descent to find** a latent vector that generates an image similar to the target image.\n",
        "\n",
        "<br>\n",
        "\n",
        "## Optional prerequisites\n",
        "\n",
        "* Familiarity with [low level Tensorflow concepts](https://www.tensorflow.org/guide/eager).\n",
        "* [Generative Adversarial Network](https://en.wikipedia.org/wiki/Generative_adversarial_network) on Wikipedia.\n",
        "* Paper on Progressive GANs: [Progressive Growing of GANs for Improved Quality, Stability, and Variation](https://arxiv.org/abs/1710.10196).\n",
        "\n",
        "### More models\n",
        "# [Here](https://tfhub.dev/s?module-type=image-generator) you can find all models currently hosted on [tfhub.dev](tfhub.dev) that can generate images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xz478AyJMn5x"
      },
      "source": [
        "# **FULL PAPER ðŸ‘‡**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBxzPwBnCddd"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGPMbishCeL9"
      },
      "source": [
        "# Install imageio for creating animations.\n",
        "# Install scikit-image for image-preprocessing.\n",
        "# Install tensorflow_docs for tensorflow documentation.\n",
        "!pip -q install imageio\n",
        "!pip -q install scikit-image\n",
        "!pip install git+https://github.com/tensorflow/docs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DtQsby9Chqw"
      },
      "source": [
        "from absl import logging\n",
        "\n",
        "import imageio\n",
        "import PIL.Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "tf.random.set_seed(0)\n",
        "\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow_docs.vis import embed\n",
        "import time\n",
        "\n",
        "try:\n",
        "  from google.colab import files\n",
        "except ImportError:\n",
        "  pass\n",
        "\n",
        "from IPython import display\n",
        "from skimage import transform\n",
        "\n",
        "# We could retrieve this value from module.get_input_shapes() if we didn't know\n",
        "# beforehand which module we will be using.\n",
        "latent_dim = 512\n",
        "\n",
        "\n",
        "# Interpolates between two vectors that are non-zero and don't both lie on a\n",
        "# line going through origin. First normalizes v2 to have the same norm as v1. \n",
        "# Then interpolates between the two vectors on the hypersphere.\n",
        "def interpolate_hypersphere(v1, v2, num_steps):\n",
        "  v1_norm = tf.norm(v1)\n",
        "  v2_norm = tf.norm(v2)\n",
        "  v2_normalized = v2 * (v1_norm / v2_norm)\n",
        "\n",
        "  vectors = []\n",
        "  for step in range(num_steps):\n",
        "    interpolated = v1 + (v2_normalized - v1) * step / (num_steps - 1)\n",
        "    interpolated_norm = tf.norm(interpolated)\n",
        "    interpolated_normalized = interpolated * (v1_norm / interpolated_norm)\n",
        "    vectors.append(interpolated_normalized)\n",
        "  return tf.stack(vectors)\n",
        "\n",
        "\n",
        "ANIM_FILE = \"./animation.gif\"\n",
        "\n",
        "# Simple way to display an image.\n",
        "def display_image(image):\n",
        "  image = tf.constant(image)\n",
        "  image = tf.image.convert_image_dtype(image, tf.uint8)\n",
        "  return PIL.Image.fromarray(image.numpy())\n",
        "\n",
        "# Given a set of images, show an animation.\n",
        "def animate(images):\n",
        "  images = np.array(images)\n",
        "  converted_images = np.clip(images * 255, 0, 255).astype(np.uint8)\n",
        "  imageio.mimsave(ANIM_FILE, converted_images)\n",
        "  return embed.embed_file(ANIM_FILE)\n",
        "\n",
        "logging.set_verbosity(logging.ERROR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85aPRFQsDWWY"
      },
      "source": [
        "# Latent space interpolation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3kh_Uw3Dbri"
      },
      "source": [
        "### Random vectors\n",
        "\n",
        "Latent space interpolation between two randomly initialized vectors. We will use a TF Hub module [progan-128](https://tfhub.dev/google/progan-128/1) that contains a pre-trained Progressive GAN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tT4FXZfDb41"
      },
      "source": [
        "# Loading up ProGAN\n",
        "\n",
        "# Why are we using ProGAN?\n",
        "# Unfortunately training Progressive GANs is a very-very computationally intensive and expensive task, and currently Google Colab only has around 12 GB RAM and 10 GB\n",
        "# GPU RAM, and for a ProGAN you need around 32 GB RAM & 16-24 GB GPU RAM, and along with the that, the GPU & CPU should be able to handle long and extensive tasks for 48+ hrs\n",
        "# And, unfortunately, Google Colab doesn't offer that high of specs, so we are using a pre-trained model by Google itself on it's high end servers.\n",
        "\n",
        "\n",
        "progan = hub.load(\"https://tfhub.dev/google/progan-128/1\").signatures['default']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_88b5zJEeQD"
      },
      "source": [
        "def interpolate_between_vectors():\n",
        "  v1 = tf.random.normal([latent_dim])\n",
        "  v2 = tf.random.normal([latent_dim])\n",
        "    \n",
        "  # Creates a tensor with 25 steps of interpolation between v1 and v2.\n",
        "  vectors = interpolate_hypersphere(v1, v2, 50)\n",
        "\n",
        "  # Uses module to generate images from the latent space.\n",
        "  interpolated_images = progan(vectors)['default']\n",
        "\n",
        "  return interpolated_images\n",
        "\n",
        "interpolated_images = interpolate_between_vectors()\n",
        "animate(interpolated_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRY05IRIEimN"
      },
      "source": [
        "## Finding closest vector in latent space\n",
        "Fix a target image. As an example use an image generated from the module or upload your own."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zF1duqkEi2J"
      },
      "source": [
        "image_from_module_space = True\n",
        "\n",
        "def get_module_space_image():\n",
        "  vector = tf.random.normal([1, latent_dim])\n",
        "  images = progan(vector)['default'][0]\n",
        "  return images\n",
        "\n",
        "def upload_image():\n",
        "  uploaded = files.upload()\n",
        "  image = imageio.imread(uploaded[list(uploaded.keys())[0]])\n",
        "  return transform.resize(image, [128, 128])\n",
        "\n",
        "if image_from_module_space:\n",
        "  target_image = get_module_space_image()\n",
        "else:\n",
        "  target_image = upload_image()\n",
        "\n",
        "display_image(target_image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWk4AKlhEp8D"
      },
      "source": [
        "After defining a loss function between the target image and the image generated by a latent space variable, we can use gradient descent to find variable values that minimize the loss."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cf_n3wmGEqVd"
      },
      "source": [
        "initial_vector = tf.random.normal([1, latent_dim])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9pTrUfEFtwq"
      },
      "source": [
        "display_image(progan(initial_vector)['default'][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmQNt665FufM"
      },
      "source": [
        "def find_closest_latent_vector(initial_vector, num_optimization_steps,\n",
        "                               steps_per_image):\n",
        "  images = []\n",
        "  losses = []\n",
        "\n",
        "  vector = tf.Variable(initial_vector)  \n",
        "  optimizer = tf.optimizers.Adam(learning_rate=0.01)\n",
        "  loss_fn = tf.losses.MeanAbsoluteError(reduction=\"sum\")\n",
        "\n",
        "  for step in range(num_optimization_steps):\n",
        "    if (step % 100)==0:\n",
        "      print()\n",
        "    print('.', end='')\n",
        "    with tf.GradientTape() as tape:\n",
        "      image = progan(vector.read_value())['default'][0]\n",
        "      if (step % steps_per_image) == 0:\n",
        "        images.append(image.numpy())\n",
        "      target_image_difference = loss_fn(image, target_image[:,:,:3])\n",
        "      # The latent vectors were sampled from a normal distribution. We can get\n",
        "      # more realistic images if we regularize the length of the latent vector to \n",
        "      # the average length of vector from this distribution.\n",
        "      regularizer = tf.abs(tf.norm(vector) - np.sqrt(latent_dim))\n",
        "      \n",
        "      loss = target_image_difference + regularizer\n",
        "      losses.append(loss.numpy())\n",
        "    grads = tape.gradient(loss, [vector])\n",
        "    optimizer.apply_gradients(zip(grads, [vector]))\n",
        "    \n",
        "  return images, losses\n",
        "\n",
        "\n",
        "num_optimization_steps=200\n",
        "steps_per_image=5\n",
        "images, loss = find_closest_latent_vector(initial_vector, num_optimization_steps, steps_per_image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRFMaO0zFvna"
      },
      "source": [
        "plt.plot(loss)\n",
        "plt.ylim([0,max(plt.ylim())])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDYNjMBYFw_p"
      },
      "source": [
        "animate(np.stack(images))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGy0yO9GFy2_"
      },
      "source": [
        "display_image(np.concatenate([images[-1], target_image], axis=1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5rY1qgxTiXC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}